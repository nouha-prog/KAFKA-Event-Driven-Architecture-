# ğŸ§© TP Kafka et Spring Cloud Stream

## ğŸ¯ Objectif
Mettre en place un environnement Kafka (local ou Docker) et dÃ©velopper une architecture complÃ¨te basÃ©e sur Spring Cloud Stream comprenant des services **Producer**, **Consumer**, **Supplier** et **Data Analytics Stream Processing**.

---

## ğŸš€ Partie 1 : Installation et Tests de Base

### 1. Installation de Kafka
- TÃ©lÃ©charger Kafka  
- DÃ©marrer **Zookeeper**
- DÃ©marrer **Kafka Server**


![img.png](screens/img.png)

---

## ğŸ³ Partie 2 : Utilisation avec Docker

### Ã‰tapes :
- CrÃ©er le fichier `docker-compose.yml`
- DÃ©marrer les conteneurs :  
  ```bash
  docker-compose up -d

![img_2.png](screens/img_2.png)
![img_1.png](screens/img_1.png)
- Tester avec :
  - `kafka-console-producer`
  - `kafka-console-consumer`

---

## âš™ï¸ Partie 3 : DÃ©veloppement avec Spring Cloud Stream
- Services Ã  crÃ©er :
- ğŸ“¨ 1. Service Producer Kafka
CrÃ©er un contrÃ´leur REST permettant dâ€™envoyer des messages Ã  un topic Kafka.

- ğŸ“¥ 2. Service Consumer Kafka

CrÃ©er un microservice qui consomme les messages envoyÃ©s par le Producer.

![img_3.png](screens/img_3.png)

![img_4.png](screens/img_4.png)

![img_5.png](screens/img_5.png)

![img_6.png](screens/img_6.png)

![img_7.png](screens/img_7.png)

- ğŸ” 3. Service Supplier Kafka
CrÃ©er un service gÃ©nÃ©rant automatiquement des messages vers Kafka (mode Supplier).

![img_8.png](screens/img_8.png)
- ğŸ“Š 4. Service de Data Analytics (Stream Processing)

Mettre en place un service Kafka Streams rÃ©alisant un traitement analytique en temps rÃ©el sur les donnÃ©es.


- ğŸŒ 5. Application Web de Visualisation
CrÃ©er une interface web affichant en temps rÃ©el les rÃ©sultats du Stream Data Analytics.

![img_9.png](screens/img_9.png)

---

## ğŸ§  RÃ©sumÃ© du TP

Ce TP permet de :

MaÃ®triser le fonctionnement de Kafka et des topics.

DÃ©ployer Kafka avec  Docker.

Construire une architecture dâ€™Ã©change de messages entre microservices.

Mettre en place un traitement analytique en temps rÃ©el.
